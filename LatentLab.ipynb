{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eWdYiMq8tmX",
        "outputId": "45d9b2e0-f2ab-4116-8719-3477ddb2d3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files in the folder:\n",
            "schaenzlin-et-al-2006-structural-design-of-a-lunar-habitat.pdf\n",
            "19770014162_update.pdf\n",
            "Space Settlements - A Design Study (1977).pdf\n",
            "system thinking 2024feb6.pptx\n",
            "Stakeholders 2022feb6.pdf\n",
            "Moon_Village_v1.1_PublicCDFStudy.pdf\n",
            "Engineering, Design and Construction of Lunar Bases ASCE paper .pdf\n",
            "Internal Pressure Level at the Lunar Base - Anna Petropoulos .pdf\n",
            "The Lunar Base Handbook'99 Chapter 16 pp. 513-539 and Chapter 17 pp. 545-560.pdf\n",
            "Habitats, Laboratories, and Airlocks pp.267-301.pdf\n",
            "Chapter 7 Lunar Base Sitting pp.205-223.pdf\n",
            "Chapter 13 pp.379-404.pdf\n",
            "Chapter 13 pp.420-422.pdf\n",
            "Chapter 5 pp. 114-151.pdf\n",
            "Space Settlements a Design Study NASA 1977 Chapter 4. Choosing Among Alternatives pp. 41-61.pdf\n",
            "Space Settlements a Design Study NASA 1977 chapter 3 Human needa in space pp. 21-36 .pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "# Path to the folder in your Google Drive\n",
        "folder_path = '/content/drive/My Drive/Space Architecture/'\n",
        "\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Print the list of files\n",
        "print(\"Files in the folder:\")\n",
        "for file in files:\n",
        "    print(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"first attempt to read in, now need to deal with image captioning but ran out of RAM\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jkq5J4fAjKX9",
        "outputId": "3b3ae7f8-65a2-4ca6-d900-983bf19f2c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first attempt to read in, now need to deal with image captioning but ran out of RAM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber openai python-magic pymupdf pytesseract\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6BeHCxI_pzi",
        "outputId": "2e006859-a737-483d-a198-3c37986b36e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.10.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting pdfminer.six==20221105 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.27.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (42.0.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: python-magic, pytesseract, pypdfium2, PyMuPDFb, h11, pymupdf, httpcore, pdfminer.six, httpx, pdfplumber, openai\n",
            "Successfully installed PyMuPDFb-1.23.22 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3 pdfminer.six-20221105 pdfplumber-0.10.4 pymupdf-1.23.26 pypdfium2-4.27.0 pytesseract-0.3.10 python-magic-0.4.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# OpenAI API Key\n",
        "api_key = \"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\"\n",
        "\n",
        "# Function to encode the image\n",
        "def encode_image(page_image):\n",
        "    img = page_image.original\n",
        "    image_data = io.BytesIO()\n",
        "    img.save(image_data, format=\"PNG\")\n",
        "    image_data.seek(0)\n",
        "    return base64.b64encode(image_data.read()).decode(\"utf-8\")\n",
        "\n",
        "# Function to generate description for an image\n",
        "def generate_image_description(page_image, title):\n",
        "    print(\"Generating for \"+title)\n",
        "    base64_image = encode_image(page_image)\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    prompt = f\"Image: {base64_image}\\nTitle: {title}\\nDescription:\"\n",
        "\n",
        "    payload = {\n",
        "      \"model\": \"gpt-4-vision-preview\",\n",
        "      \"messages\": [\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "            {\n",
        "              \"type\": \"text\",\n",
        "              \"text\": \"What’s in this image?\"\n",
        "            },\n",
        "            {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\n",
        "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"max_tokens\": 100\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "    response_json = response.json()\n",
        "    if 'choices' in response_json and len(response_json['choices']) > 0:\n",
        "      description = response_json['choices'][0]['message']['content']\n",
        "      print(description)\n",
        "    else:\n",
        "      print(response_json,\"No description found in the response.\")\n",
        "      return\n",
        "\n",
        "    return description\n",
        "\n",
        "# # Assuming 'images' is a list of tuples containing PageImage objects and titles\n",
        "# for page_image, title in images:\n",
        "#   description = generate_image_description(page_image, title)\n",
        "\n"
      ],
      "metadata": {
        "id": "giGAssOnRNuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "import re\n",
        "\n",
        "def extract_sections_and_images_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        pages = []\n",
        "        images = []\n",
        "\n",
        "        for page_num in range(9,10):  # Process only the first 10 pages for demonstration\n",
        "            page = pdf.pages[page_num]\n",
        "\n",
        "            left_rectangle = (10, 0, page.width / 2, page.height-50)\n",
        "            left_text = page.crop(left_rectangle).extract_text(layout=False)\n",
        "\n",
        "            right_rectangle = (page.width / 2, 0, page.width, page.height)\n",
        "            right_text = page.crop(right_rectangle).extract_text(layout=False)\n",
        "\n",
        "            pages.append(left_text+right_text)\n",
        "\n",
        "            page_images = page.images\n",
        "\n",
        "            descriptions={}\n",
        "            for img in page_images:\n",
        "                image_bbox = (img['x0'], page.height - img['y1'], img['x1'], page.height - img['y0'])\n",
        "                caption_bbox = (max(0,img['x0']-50), page.height - img['y1'], img['x1'], min(792,page.height - img['y1'] + 600))\n",
        "                caption_text = page.crop(caption_bbox).extract_text()\n",
        "                caption_regex = r\"Fig\\.\\s*\\d+\\..*\"\n",
        "                caption = \"None\"\n",
        "                for line in caption_text.split(\"\\n\"):\n",
        "                    match = re.match(caption_regex, line)\n",
        "                    if match:\n",
        "                        caption = match.group(0)\n",
        "                        break\n",
        "\n",
        "                cropped_page = page.crop(image_bbox)\n",
        "                image_obj = cropped_page.to_image(resolution=400)\n",
        "                images.append((image_obj, caption))\n",
        "\n",
        "            print(len(images))\n",
        "            for page_image, title in images:\n",
        "                # Placeholder for generative model integration to get description\n",
        "                description = generate_image_description(page_image, title)\n",
        "                #description=\"HI\"\n",
        "                descriptions[title] = description\n",
        "\n",
        "            for i, page_text in enumerate(pages):\n",
        "              for title, description in descriptions.items():\n",
        "                  if title in page_text:\n",
        "                      #print(\"YES!\",title,i)\n",
        "                      new_page_text = page_text.replace(title, title + \" GPT GENERATED Visual Description: \" + description)\n",
        "                      #print(new_page_text)\n",
        "                      pages[i] = new_page_text\n",
        "\n",
        "    # for img, title in images:\n",
        "    #     display(img)\n",
        "    #     print(\"Title:\", title)\n",
        "    #     print(\"------------\")\n",
        "\n",
        "    return pages, images\n",
        "\n",
        "pdf_path = \"/content/drive/My Drive/Space Architecture/schaenzlin-et-al-2006-structural-design-of-a-lunar-habitat.pdf\"\n",
        "\n",
        "pages, images = extract_sections_and_images_from_pdf(pdf_path)\n",
        "\n",
        "# Print the sections\n",
        "for i, page in enumerate(pages, start=1):\n",
        "    page10text=page\n",
        "    print(f\"Page {i}:\", page)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le-mTk6zROk9",
        "outputId": "2cdac41f-c91d-4c8f-ee21-de7bc3f8a4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Generating for Fig.8.Three-hingedarchsystem\n",
            "The image displays a simple line drawing of a semicircular arc with three circles placed at distinct points: one at each end of the diameter of the semicircle, and one at the top, at the midpoint of the arc. It appears to be a geometrical illustration, possibly for educational purposes, representing a semicircle and specific points along its circumference.\n",
            "Generating for Fig. 9. Cross section of a lava tube with a possible habit\n",
            "The image shows a conceptual cross-section drawing of a habitat module placed inside a lava tube. A lava tube is a natural tunnel formed by flowing lava that can create a sizable void beneath the surface once the lava flow stops and the remaining lava drains away or cools down. These tubes can provide natural protection from radiation, micrometeorites, and temperature extremes, making them potentially attractive locations for constructing habitats in planetary exploration scenarios, like on the Moon or Mars.\n",
            "\n",
            "In the drawing, you can see the\n",
            "Generating for None\n",
            "This image appears to show a model or artistic concept of a space base or colony, potentially on the surface of the Moon or another celestial body. There are several modules connected via tube-like structures, which could represent living quarters, laboratories, or other facilities. The use of the name \"KOPERNIKUS\" on the structures suggests it may be a fictional or theoretical project, possibly named in honor of the astronomer Nicolaus Copernicus.\n",
            "\n",
            "The image is not very clear, likely due to\n",
            "Generating for Fig.11.“Tycho-Sphere”(cid:1)LunarBaseDesignWorkshop2002Tea\n",
            "This image appears to show an X-ray or some kind of scan of a spherical object. Based on the complexity and artificial nature of the structures inside, this could be an image of a mechanical or electronic device encapsulated within a spherical shell. The internal components are visible as various shapes and densities within the sphere, but due to the monochrome and somewhat blurry nature of the image, it is challenging to determine the exact function or identity of the object or its contents. However, given the spherical casing and\n",
            "Page 1: Fig.8.Three-hingedarchsystem\n",
            "Roof thickness in excess of 10m will provide safe and long-\n",
            "term shelter against radiation and meteoroid collisions. Concerns\n",
            "of material degradation, thermal fatigue, and related exposure\n",
            "problemsaremoderatedornegated.Forfirstapplications,prefab-\n",
            "ricated habitats would use lava tubes as shelters against environ-\n",
            "mental hazards. Later, it might be possible to modify the lava\n",
            "tubes to function as habitats. Geometry, surface roughness, air\n",
            "tightness,andotherproblemswillhavetobeaddressed.Reliabil-\n",
            "ity of the cavern roof is a major concern.\n",
            "Constructingahabitatinsidealavatubecanbeachievedusing\n",
            "extremely lightweight material, since it does not have to support\n",
            "any shielding material whatsoever. Inflatable solutions seem the\n",
            "mostpromising.Acrosssectionofapossiblearrangementcanbe\n",
            "seeninFig.9.Accessibility,lighting,andotherarchitecturalprob-\n",
            "lems of a base inside a lava tube need a satisfying solution for\n",
            "each individual site (cid:1)Daga and Daga 1988(cid:2). Human factors and\n",
            "human psychology are issues for further research.\n",
            "Lunar Base Design Workshop Zippert 2004\n",
            "„ …\n",
            "In the Summer of 2002, an international team of experts, spon-\n",
            "sored by ESA, held the first “Lunar Base Design Workshop” in\n",
            "theNetherlandsandAustria.Architecturestudentsfrom16coun-\n",
            "triesdesignedlunarbaseswithastrongemphasisonarchitectural\n",
            "problems.Attheendoftheworkshop,theseventeamspresented\n",
            "distinctively different and new approaches for lunar habitats.\n",
            "Fig. 10 shows the result of team Kopernikus, using inflatable\n",
            "cells to expand the habitable volume of the hard-shell main\n",
            "structure.\n",
            "Fig. 9. Cross section of a lava tube with a possible habitat\n",
            "arrangement(cid:1)Dagaetal.1992(cid:2)Fig. 10. Model of the Kopernikus Lunar Base (cid:1)Lunar Base Design\n",
            "Workshop Team Kopernikus; Lunar Base Design Workshop 2002 at\n",
            "ESA-ESTEC HBT–VUT, Vienna, Austria (cid:3)www.liquifer.at(cid:4)(cid:2)\n",
            "(cid:1)LIQUIFER2002(cid:2)\n",
            "The design of team Tycho is also very interesting. A mobile\n",
            "triple-layer sphere provides habitation for workers mining 3He.\n",
            "The sphere can move; pumping the water between the inner two\n",
            "membrane layers. The room between the outer and the middle\n",
            "layer is used for storage and vehicles (cid:1)see Fig. 11(cid:2).\n",
            "Theseandalltheotherconceptspresentedattheworkshopare\n",
            "very interesting and promising, most of them taking radical new\n",
            "approaches.However,theylackpreciseengineeringsolutionsand\n",
            "most of them do not address all lunar problems, which is only\n",
            "natural at this stage of the design.\n",
            "Concept Evaluation\n",
            "Evaluation Criteria\n",
            "Evaluating structural concepts for a lunar base is a very difficult\n",
            "task. There are so many things about construction on the Moon\n",
            "Fig.11.“Tycho-Sphere”(cid:1)LunarBaseDesignWorkshop2002Tea GPT GENERATED Visual Description: This image appears to show an X-ray or some kind of scan of a spherical object. Based on the complexity and artificial nature of the structures inside, this could be an image of a mechanical or electronic device encapsulated within a spherical shell. The internal components are visible as various shapes and densities within the sphere, but due to the monochrome and somewhat blurry nature of the image, it is challenging to determine the exact function or identity of the object or its contents. However, given the spherical casing andm\n",
            "Tycho; photo, Franz Schachinger; Lunar Base Design\n",
            "Workshop 2002 at ESA-ESTEG, HB2–VUT, Vienna, Austria\n",
            "(cid:3)www.liguifer.at(cid:4)(cid:2)(cid:1)LIQUIFER2002(cid:2)\n",
            "006, 19(3): 133-157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for page_image,title in images:\n",
        "  PILIMAGE=page_image.original\n",
        "  print(PILIMAGE)"
      ],
      "metadata": {
        "id": "nm0wVYXgbT9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page10text.replace(\"\\n\", \" \"))"
      ],
      "metadata": {
        "id": "1lpc30uAjtgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08aecbf-64bb-41df-85d5-82e0da6161f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fig.8.Three-hingedarchsystem Roof thickness in excess of 10m will provide safe and long- term shelter against radiation and meteoroid collisions. Concerns of material degradation, thermal fatigue, and related exposure problemsaremoderatedornegated.Forfirstapplications,prefab- ricated habitats would use lava tubes as shelters against environ- mental hazards. Later, it might be possible to modify the lava tubes to function as habitats. Geometry, surface roughness, air tightness,andotherproblemswillhavetobeaddressed.Reliabil- ity of the cavern roof is a major concern. Constructingahabitatinsidealavatubecanbeachievedusing extremely lightweight material, since it does not have to support any shielding material whatsoever. Inflatable solutions seem the mostpromising.Acrosssectionofapossiblearrangementcanbe seeninFig.9.Accessibility,lighting,andotherarchitecturalprob- lems of a base inside a lava tube need a satisfying solution for each individual site (cid:1)Daga and Daga 1988(cid:2). Human factors and human psychology are issues for further research. Lunar Base Design Workshop Zippert 2004 „ … In the Summer of 2002, an international team of experts, spon- sored by ESA, held the first “Lunar Base Design Workshop” in theNetherlandsandAustria.Architecturestudentsfrom16coun- triesdesignedlunarbaseswithastrongemphasisonarchitectural problems.Attheendoftheworkshop,theseventeamspresented distinctively different and new approaches for lunar habitats. Fig. 10 shows the result of team Kopernikus, using inflatable cells to expand the habitable volume of the hard-shell main structure. Fig. 9. Cross section of a lava tube with a possible habitat arrangement(cid:1)Dagaetal.1992(cid:2)Fig. 10. Model of the Kopernikus Lunar Base (cid:1)Lunar Base Design Workshop Team Kopernikus; Lunar Base Design Workshop 2002 at ESA-ESTEC HBT–VUT, Vienna, Austria (cid:3)www.liquifer.at(cid:4)(cid:2) (cid:1)LIQUIFER2002(cid:2) The design of team Tycho is also very interesting. A mobile triple-layer sphere provides habitation for workers mining 3He. The sphere can move; pumping the water between the inner two membrane layers. The room between the outer and the middle layer is used for storage and vehicles (cid:1)see Fig. 11(cid:2). Theseandalltheotherconceptspresentedattheworkshopare very interesting and promising, most of them taking radical new approaches.However,theylackpreciseengineeringsolutionsand most of them do not address all lunar problems, which is only natural at this stage of the design. Concept Evaluation Evaluation Criteria Evaluating structural concepts for a lunar base is a very difficult task. There are so many things about construction on the Moon Fig.11.“Tycho-Sphere”(cid:1)LunarBaseDesignWorkshop2002Tea GPT GENERATED Visual Description: This image appears to show an X-ray or some kind of scan of a spherical object. Based on the complexity and artificial nature of the structures inside, this could be an image of a mechanical or electronic device encapsulated within a spherical shell. The internal components are visible as various shapes and densities within the sphere, but due to the monochrome and somewhat blurry nature of the image, it is challenging to determine the exact function or identity of the object or its contents. However, given the spherical casing andm Tycho; photo, Franz Schachinger; Lunar Base Design Workshop 2002 at ESA-ESTEG, HB2–VUT, Vienna, Austria (cid:3)www.liguifer.at(cid:4)(cid:2)(cid:1)LIQUIFER2002(cid:2) 006, 19(3): 133-157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge Graph"
      ],
      "metadata": {
        "id": "R-MfL2x1hkvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers wikipedia newspaper3k GoogleNews pyvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5vhPmIQhkT4",
        "outputId": "f660ad10-fd79-4de0-8f9a-675a375541eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: GoogleNews in /usr/local/lib/python3.10/dist-packages (1.6.13)\n",
            "Requirement already satisfied: pyvis in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (5.1.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.10/dist-packages (from GoogleNews) (1.2.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.3)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.0.3)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser->GoogleNews) (2023.4)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser->GoogleNews) (5.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import math\n",
        "import torch\n",
        "import wikipedia\n",
        "from newspaper import Article, ArticleException\n",
        "from GoogleNews import GoogleNews\n",
        "import IPython\n",
        "from pyvis.network import Network\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
      ],
      "metadata": {
        "id": "gdHtlfRhhqdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_relations_from_model_output(text):\n",
        "    relations = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
        "    for token in text_replaced.split():\n",
        "        if token == \"<triplet>\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                relations.append({\n",
        "                    'head': subject.strip(),\n",
        "                    'type': relation.strip(),\n",
        "                    'tail': object_.strip()\n",
        "                })\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"<subj>\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                relations.append({\n",
        "                    'head': subject.strip(),\n",
        "                    'type': relation.strip(),\n",
        "                    'tail': object_.strip()\n",
        "                })\n",
        "            object_ = ''\n",
        "        elif token == \"<obj>\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        relations.append({\n",
        "            'head': subject.strip(),\n",
        "            'type': relation.strip(),\n",
        "            'tail': object_.strip()\n",
        "        })\n",
        "    return relations"
      ],
      "metadata": {
        "id": "Jhj_WoMghy5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.entities = {}\n",
        "        self.relations = []\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")\n",
        "\n",
        "    def merge_relations(self, r1):\n",
        "        r2 = [r for r in self.relations\n",
        "              if self.are_relations_equal(r1, r)][0]\n",
        "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n",
        "                        if span not in r2[\"meta\"][\"spans\"]]\n",
        "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "        else:\n",
        "            self.merge_relations(r)\n",
        "\n",
        "    # def get_wikipedia_data(self, candidate_entity):\n",
        "    #     try:\n",
        "    #         page = wikipedia.page(candidate_entity, auto_suggest=False)\n",
        "    #         entity_data = {\n",
        "    #             \"title\": page.title,\n",
        "    #             \"url\": page.url,\n",
        "    #             \"summary\": page.summary\n",
        "    #         }\n",
        "    #         return entity_data\n",
        "    #     except:\n",
        "    #         return None\n",
        "\n",
        "    # def add_entity(self, e):\n",
        "    #     self.entities[e[\"title\"]] = {k:v for k,v in e.items() if k != \"title\"}\n",
        "\n",
        "    # def add_relation(self, r):\n",
        "    #     # check on wikipedia\n",
        "    #     candidate_entities = [r[\"head\"], r[\"tail\"]]\n",
        "    #     entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]#NO!!!! THiS IS BAD.\n",
        "\n",
        "    #     # if one entity does not exist, stop\n",
        "    #     if any(ent is None for ent in entities):\n",
        "    #         return\n",
        "\n",
        "    #     # manage new entities\n",
        "    #     for e in entities:\n",
        "    #         self.add_entity(e)\n",
        "\n",
        "    #     # rename relation entities with their wikipedia titles\n",
        "    #     r[\"head\"] = entities[0][\"title\"]\n",
        "    #     r[\"tail\"] = entities[1][\"title\"]\n",
        "\n",
        "    #     # manage new relation\n",
        "    #     if not self.exists_relation(r):\n",
        "    #         self.relations.append(r)\n",
        "    #     else:\n",
        "    #         self.merge_relations(r)\n",
        "\n",
        "    # def print(self):\n",
        "    #     print(\"Entities:\")\n",
        "    #     for e in self.entities.items():\n",
        "    #         print(f\"  {e}\")\n",
        "    #     print(\"Relations:\")\n",
        "    #     for r in self.relations:\n",
        "    #         print(f\"  {r}\")\n"
      ],
      "metadata": {
        "id": "_wmJi4PYjS35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_small_text_to_kb(text, verbose=False):\n",
        "    kb = KB()\n",
        "\n",
        "    # Tokenizer text\n",
        "    model_inputs = tokenizer(text, max_length=512, padding=True, truncation=True,\n",
        "                            return_tensors='pt')\n",
        "    if verbose:\n",
        "        print(f\"Num tokens: {len(model_inputs['input_ids'][0])}\")\n",
        "\n",
        "    # Generate\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 216,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": 3\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **model_inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    for sentence_pred in decoded_preds:\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for r in relations:\n",
        "            kb.add_relation(r)\n",
        "\n",
        "    return kb"
      ],
      "metadata": {
        "id": "iMqLH64CjX0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_text_to_kb(text, span_length=128, verbose=False):\n",
        "    # tokenize whole text\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
        "\n",
        "    # compute span boundaries\n",
        "    num_tokens = len(inputs[\"input_ids\"][0])\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_tokens} tokens\")\n",
        "    num_spans = math.ceil(num_tokens / span_length)\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_spans} spans\")\n",
        "    overlap = math.ceil((num_spans * span_length - num_tokens) /\n",
        "                        max(num_spans - 1, 1))\n",
        "    spans_boundaries = []\n",
        "    start = 0\n",
        "    for i in range(num_spans):\n",
        "        spans_boundaries.append([start + span_length * i,\n",
        "                                 start + span_length * (i + 1)])\n",
        "        start -= overlap\n",
        "    if verbose:\n",
        "        print(f\"Span boundaries are {spans_boundaries}\")\n",
        "\n",
        "    # transform input with spans\n",
        "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
        "                  for boundary in spans_boundaries]\n",
        "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
        "                    for boundary in spans_boundaries]\n",
        "    inputs = {\n",
        "        \"input_ids\": torch.stack(tensor_ids),\n",
        "        \"attention_mask\": torch.stack(tensor_masks)\n",
        "    }\n",
        "\n",
        "    # generate relations\n",
        "    num_return_sequences = 3\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 256,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": num_return_sequences\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "\n",
        "    # decode relations\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
        "                                           skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    kb = KB()\n",
        "    i = 0\n",
        "    for sentence_pred in decoded_preds:\n",
        "        current_span_index = i // num_return_sequences\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for relation in relations:\n",
        "            relation[\"meta\"] = {\n",
        "                \"spans\": [spans_boundaries[current_span_index]]\n",
        "            }\n",
        "            kb.add_relation(relation)\n",
        "        i += 1\n",
        "\n",
        "    return kb"
      ],
      "metadata": {
        "id": "kuD4YK-xjq2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page10text=page10text.replace(\"\\n\", \" \")\n",
        "kb = from_text_to_kb(page10text, verbose=True)\n",
        "kb.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w0pREHYjB9S",
        "outputId": "2a1a97be-83f6-4d97-9f88-fb335516896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input has 889 tokens\n",
            "Input has 7 spans\n",
            "Span boundaries are [[0, 128], [126, 254], [252, 380], [378, 506], [504, 632], [630, 758], [756, 884]]\n",
            "Relations:\n",
            "  {'head': 'roof', 'type': 'part of', 'tail': 'Roof thickness', 'meta': {'spans': [[0, 128]]}}\n",
            "  {'head': 'Roof thickness', 'type': 'part of', 'tail': 'Roof', 'meta': {'spans': [[0, 128]]}}\n",
            "  {'head': 'Roof thickness', 'type': 'has part', 'tail': 'roof', 'meta': {'spans': [[0, 128]]}}\n",
            "  {'head': 'Lunar Base Design Workshop', 'type': 'inception', 'tail': '1988', 'meta': {'spans': [[126, 254]]}}\n",
            "  {'head': 'Daga and Daga 1988', 'type': 'point in time', 'tail': '1988', 'meta': {'spans': [[126, 254]]}}\n",
            "  {'head': 'Lunar Base Design Workshop', 'type': 'point in time', 'tail': '1988', 'meta': {'spans': [[126, 254]]}}\n",
            "  {'head': 'Workshop Zippert 2004', 'type': 'point in time', 'tail': '2004', 'meta': {'spans': [[252, 380]]}}\n",
            "  {'head': 'Workshop Zippert', 'type': 'point in time', 'tail': '2004', 'meta': {'spans': [[252, 380]]}}\n",
            "  {'head': 'Workshop Zippert 2004', 'type': 'point in time', 'tail': '2002', 'meta': {'spans': [[252, 380]]}}\n",
            "  {'head': 'HBT–VUT', 'type': 'located in the administrative territorial entity', 'tail': 'Vienna', 'meta': {'spans': [[378, 506]]}}\n",
            "  {'head': 'ESA-ESTEC HBT–VUT', 'type': 'located in the administrative territorial entity', 'tail': 'Vienna', 'meta': {'spans': [[378, 506]]}}\n",
            "  {'head': 'HBT–VUT', 'type': 'country', 'tail': 'Austria', 'meta': {'spans': [[378, 506]]}}\n",
            "  {'head': 'Vienna', 'type': 'country', 'tail': 'Austria', 'meta': {'spans': [[378, 506], [756, 884]]}}\n",
            "  {'head': 'Austria', 'type': 'contains administrative territorial entity', 'tail': 'Vienna', 'meta': {'spans': [[378, 506], [756, 884]]}}\n",
            "  {'head': 'Tycho', 'type': 'product or material produced', 'tail': '3He', 'meta': {'spans': [[504, 632]]}}\n",
            "  {'head': 'Tycho', 'type': 'field of work', 'tail': '3He', 'meta': {'spans': [[504, 632]]}}\n",
            "  {'head': 'Tycho', 'type': 'uses', 'tail': '3He', 'meta': {'spans': [[504, 632]]}}\n",
            "  {'head': 'Tycho-Sphere', 'type': 'instance of', 'tail': 'lunar base', 'meta': {'spans': [[630, 758]]}}\n",
            "  {'head': 'LunarBaseDesignWorkshop2002Tea GPT GENERATED Visual Description', 'type': 'depicts', 'tail': 'lunar base', 'meta': {'spans': [[630, 758]]}}\n",
            "  {'head': 'LunarBaseDesignWorkshop2002Tea GPT GENERATED Visual Description', 'type': 'part of', 'tail': 'LunarBaseDesignWorkshop2002Tea GPT GENERATED Visual Description', 'meta': {'spans': [[630, 758]]}}\n",
            "  {'head': 'HB2–VUT', 'type': 'located in the administrative territorial entity', 'tail': 'Vienna', 'meta': {'spans': [[756, 884]]}}\n",
            "  {'head': 'HB2–VUT', 'type': 'country', 'tail': 'Austria', 'meta': {'spans': [[756, 884]]}}\n",
            "  {'head': 'HB2–VUT', 'type': 'located in the administrative territorial entity', 'tail': 'Vienna, Austria', 'meta': {'spans': [[756, 884]]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bad."
      ],
      "metadata": {
        "id": "iQsL7MqBxHrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/rahulnyk/knowledge_graph/blob/main/extract_graph.ipynb"
      ],
      "metadata": {
        "id": "hpNXT57vw_vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install langchain\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pathlib import Path\n",
        "import random\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGyr6mnPxaIZ",
        "outputId": "27134e17-9164-4c97-b5d3-df55f6da7939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.10-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.28 (from langchain)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
            "  Downloading langsmith-0.1.14-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-text-splitters-0.0.1 langsmith-0.1.14 marshmallow-3.21.0 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n"
          ]
        }
      ]
    }
  ]
}